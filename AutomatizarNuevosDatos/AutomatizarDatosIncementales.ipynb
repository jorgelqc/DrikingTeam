{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería que vamos a usar para la automatización del monitoreo de los datos, es Watchdog. Estuvimos averiguando y es una muy buena herramienta para identificar cambios en el sistema de archivos en tiempo real. Es particularmente útil cuando necesitas realizar acciones automáticas en respuesta a eventos como la creación, modificación, o eliminación de archivos y directorios. Es por eso, que nos decidimos por Watchdog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para interactual con la base de datos, vamos a usar pyodbc en conjunto con Sqlalchemy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importacion de librerias usadas\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy import exc\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from sqlalchemy.engine import reflection\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "from watchdog.events import PatternMatchingEventHandler\n",
    "from watchdog.observers import Observer\n",
    "import os\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de la cadena de conexión con la base de datos \n",
    "server = r'JORGE\\SQLEXPRESS'\n",
    "database = 'DrinkingTeamDB'\n",
    "username = 'datafusionlatam'\n",
    "password = 'DAFTHENRY'\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "try:\n",
    "    engine = create_engine(f'mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server')\n",
    "    conn = engine.connect()\n",
    "except SQLAlchemyError as e:\n",
    "    print(f\"Error al conectar a la base de datos: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codigo automatizado de ingreso de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV modificado: C:\\datos\\datos_productos.csv\n",
      "Procesando la tabla : Productos, usando las columna Marca\n",
      "Columnas en el DataFrame: ['Marca', 'Nombre', 'Volumen']\n",
      "Comparando valores en la columna Marca con last_ingestion_id: 80\n",
      "Valores en la columna Marca:\n",
      "0    81.0\n",
      "1    82.0\n",
      "Name: Marca, dtype: float64\n",
      "Nuevos datos encontrados para la tabla Productos:\n",
      "   Marca       Nombre Volumen\n",
      "0   81.0       Fernet   Litro\n",
      "1   82.0  Aguardiente   750ml\n",
      "Datos ingresados con éxito en la tabla y en ingestion_control\n",
      "Proceso de monitoreo finalizado.\n"
     ]
    }
   ],
   "source": [
    "class MyHandler(FileSystemEventHandler):\n",
    "    def __init__(self, observer, ruta_datos):\n",
    "        self.observer = observer\n",
    "        self.ruta_datos = ruta_datos\n",
    "        self.table_map = {\n",
    "            r\"C:\\datos\\datos_tiendas.csv\": ('Tiendas', 'NumeroTienda'),\n",
    "            r\"C:\\datos\\datos_proveedores.csv\": ('Proveedores', 'Nombre'),\n",
    "            r\"C:\\datos\\datos_productos.csv\": ('Productos', 'Marca')\n",
    "        }\n",
    "\n",
    "    def on_modified(self, event):\n",
    "        if event.src_path.endswith('.csv'):\n",
    "            print(f\"Archivo CSV modificado: {event.src_path}\")\n",
    "            df = pd.read_csv(event.src_path, dtype={self.table_map[event.src_path][1]:float}, header=0)\n",
    "            tabla, primera_columna = self.table_map.get(event.src_path, (None, None))\n",
    "            print(f\"Procesando la tabla : {tabla}, usando las columna {primera_columna}\")\n",
    "            print(f\"Columnas en el DataFrame: {df.columns.tolist()}\")\n",
    "\n",
    "            if tabla and primera_columna:\n",
    "                self.ingresar_datos(df, tabla, primera_columna)\n",
    "                # Detenemos el observador después de procesar el archivo\n",
    "                self.observer.stop()\n",
    "            else:\n",
    "                print(f\"No se encontró una tabla asociada para {event.src_path}\")\n",
    "\n",
    "    def ingresar_datos(self, df, tabla, primera_columna):\n",
    "        try:\n",
    "            # Obtén el último id de ingesta desde la tabla ingestion_control\n",
    "            query = f\"SELECT MAX(last_ingestion_id) AS last_id FROM ingestion_control WHERE table_name = '{tabla}'\"\n",
    "            last_ingestion_id = pd.read_sql(query, conn).iloc[0, 0]\n",
    "            last_ingestion_id = last_ingestion_id if last_ingestion_id is not None else 0\n",
    "            print(f\"Comparando valores en la columna {primera_columna} con last_ingestion_id: {last_ingestion_id}\")\n",
    "            print(f\"Valores en la columna {primera_columna}:\\n{df[primera_columna].head()}\")\n",
    "\n",
    "\n",
    "            # Filtra los datos nuevos\n",
    "            new_data = df[df[primera_columna] > last_ingestion_id].copy()\n",
    "            print(f\"Nuevos datos encontrados para la tabla {tabla}:\\n{new_data}\")\n",
    "\n",
    "\n",
    "            # Asegúrate de que se está asignando last_ingestion_id correctamente\n",
    "            new_data['last_ingestion_id'] = new_data[primera_columna]\n",
    "\n",
    "            if not new_data.empty:\n",
    "                # Inserta los nuevos datos en la tabla correspondiente\n",
    "                new_data.to_sql(tabla, engine, if_exists='append', index=False)\n",
    "\n",
    "                last_processed_id = int(new_data[primera_columna].max())\n",
    "\n",
    "                # Inserta el nuevo registro en la tabla ingestion_control\n",
    "                insert_query = text(\"\"\"\n",
    "                    INSERT INTO ingestion_control (last_ingestion_id, created_at, updated_at, table_name)\n",
    "                    VALUES (:last_ingestion_id, :created_at, :updated_at, :table_name)\n",
    "                \"\"\")\n",
    "                with engine.begin() as connection:\n",
    "                    connection.execute(insert_query, {\n",
    "                        'last_ingestion_id': last_processed_id,\n",
    "                        'created_at': datetime.datetime.now(),\n",
    "                        'updated_at': datetime.datetime.now(),\n",
    "                        'table_name': tabla\n",
    "                    })\n",
    "                print(\"Datos ingresados con éxito en la tabla y en ingestion_control\")\n",
    "\n",
    "            else:\n",
    "                print(\"No hay nuevos datos para insertar.\")\n",
    "        except exc.SQLAlchemyError as e:\n",
    "            print(f\"Error durante la ingesta de datos: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ruta_datos = r\"C:\\datos\"\n",
    "    observer = Observer()\n",
    "    event_handler = MyHandler(observer, ruta_datos)\n",
    "    observer.schedule(event_handler, ruta_datos, recursive=True)\n",
    "    observer.start()\n",
    "\n",
    "    # Espera a que el observador se detenga\n",
    "    observer.join()\n",
    "    print(\"Proceso de monitoreo finalizado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
